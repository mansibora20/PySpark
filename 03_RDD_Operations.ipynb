{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOnws2lCbFrx9EmKqoKDrVL",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mansibora20/PySpark/blob/main/03_RDD_Operations.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "mk34Xlym0l5s"
      },
      "outputs": [],
      "source": [
        "from pyspark.sql import SparkSession\n",
        "from pyspark import SparkContext"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step 1: Initialize Spark Session\n",
        "Creating a Spark session and obtaining the SparkContext"
      ],
      "metadata": {
        "id": "6U7UNnDk0uUL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "spark = SparkSession.builder \\\n",
        "    .appName(\"PySpark RDD Basics\") \\\n",
        "    .getOrCreate()\n",
        "sc = spark.sparkContext\n"
      ],
      "metadata": {
        "id": "JtFiWhBx0m7e"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step 2: Create an RDD from a list\n",
        "Parallelizing a Python list to create an RDD\n",
        "* RDDs (Resilient Distributed Datasets) are the fundamental data structure of Apache Spark.\n",
        "* We create an RDD by parallelizing a Python list."
      ],
      "metadata": {
        "id": "30aIVoHk0z7q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]\n",
        "rdd = sc.parallelize(data)"
      ],
      "metadata": {
        "id": "6SBlaA-v0xOi"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step 3: RDD Transformations\n",
        "Applying transformations on RDD.\n",
        "* Transformations create a new RDD from an existing one.\n",
        "* Transformations are **lazy**, meaning they are not executed until an action is called.\n",
        "1. Map Transformation: Applies a function to each element in the RDD.\n",
        "2. Filter Transformation: Filters elements based on a condition.\n",
        "3. FlatMap Transformation: Each input item can be mapped to multiple output items.\n",
        "4. Distinct Transformation: Removes duplicate elements.\n",
        "5. Sample Transformation: Randomly selects a fraction of the data.\n",
        "\n"
      ],
      "metadata": {
        "id": "qdMKQcCa06zu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Map: Multiply each element by 2\n",
        "rdd_map = rdd.map(lambda x: x * 2)\n",
        "print(\"Mapped RDD:\", rdd_map.collect())\n",
        "\n",
        "# Filter: Keep only even numbers\n",
        "rdd_filter = rdd.filter(lambda x: x % 2 == 0)\n",
        "print(\"Filtered RDD:\", rdd_filter.collect())\n",
        "\n",
        "# FlatMap: Flatten the elements\n",
        "rdd_flatmap = rdd.flatMap(lambda x: (x, x*10))\n",
        "print(\"FlatMapped RDD:\", rdd_flatmap.collect())\n",
        "\n",
        "# Distinct: Remove duplicate elements\n",
        "rdd_distinct = rdd.distinct()\n",
        "print(\"Distinct RDD:\", rdd_distinct.collect())\n",
        "\n",
        "# Sample: Randomly sample 50% of the data\n",
        "rdd_sample = rdd.sample(False, 0.5, seed=42)\n",
        "print(\"Sampled RDD:\", rdd_sample.collect())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Pz3DsAiy034R",
        "outputId": "073101ee-1d11-4bb8-a5c3-6df36518a26c"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mapped RDD: [2, 4, 6, 8, 10, 12, 14, 16, 18, 20]\n",
            "Filtered RDD: [2, 4, 6, 8, 10]\n",
            "FlatMapped RDD: [1, 10, 2, 20, 3, 30, 4, 40, 5, 50, 6, 60, 7, 70, 8, 80, 9, 90, 10, 100]\n",
            "Distinct RDD: [2, 4, 6, 8, 10, 1, 3, 5, 7, 9]\n",
            "Sampled RDD: [1, 2, 4, 5]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step 4: RDD Actions\n",
        "Actions trigger the execution of transformations and return results"
      ],
      "metadata": {
        "id": "A_1vy-Rz2Cvz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "rdd_collect = rdd.collect()  # Collect all elements\n",
        "print(\"Original RDD:\", rdd_collect)\n",
        "\n",
        "rdd_count = rdd.count()  # Count the number of elements\n",
        "print(\"RDD Count:\", rdd_count)\n",
        "\n",
        "rdd_first = rdd.first()  # Get the first element\n",
        "print(\"First Element:\", rdd_first)\n",
        "\n",
        "rdd_take = rdd.take(5)  # Take first 5 elements\n",
        "print(\"First 5 Elements:\", rdd_take)\n",
        "\n",
        "rdd_max = rdd.max()  # Get max value\n",
        "print(\"Max Value:\", rdd_max)\n",
        "\n",
        "rdd_min = rdd.min()  # Get min value\n",
        "print(\"Min Value:\", rdd_min)\n",
        "\n",
        "rdd_sum = rdd.sum()  # Compute sum\n",
        "print(\"Sum of Elements:\", rdd_sum)\n",
        "\n",
        "rdd_mean = rdd.mean()  # Compute mean\n",
        "print(\"Mean Value:\", rdd_mean)\n",
        "\n",
        "rdd_variance = rdd.variance()  # Compute variance\n",
        "print(\"Variance:\", rdd_variance)\n",
        "\n",
        "rdd_stdev = rdd.stdev()  # Compute standard deviation\n",
        "print(\"Standard Deviation:\", rdd_stdev)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xeft2hGT1P1X",
        "outputId": "30febaaf-9c76-469f-f702-d0b1ae8532c5"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original RDD: [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]\n",
            "RDD Count: 10\n",
            "First Element: 1\n",
            "First 5 Elements: [1, 2, 3, 4, 5]\n",
            "Max Value: 10\n",
            "Min Value: 1\n",
            "Sum of Elements: 55\n",
            "Mean Value: 5.5\n",
            "Variance: 8.25\n",
            "Standard Deviation: 2.8722813232690143\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step 5: Key-Value RDDs\n",
        "Creating an RDD with key-value pairs.\n",
        "* Key-Value RDDs allow operations like grouping and aggregating by key."
      ],
      "metadata": {
        "id": "RkcjFhzK2Pxp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data_kv = [(\"a\", 1), (\"b\", 2), (\"a\", 3), (\"b\", 4), (\"c\", 5)]\n",
        "rdd_kv = sc.parallelize(data_kv)"
      ],
      "metadata": {
        "id": "TxK86vI62LU0"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "Performing operations on key-value RDDs"
      ],
      "metadata": {
        "id": "UHrgrl2i2Xcf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "rdd_groupby = rdd_kv.groupByKey().mapValues(list).collect()  # Grouping by key\n",
        "print(\"Grouped by Key:\", rdd_groupby)\n",
        "\n",
        "rdd_reduceby = rdd_kv.reduceByKey(lambda x, y: x + y).collect()  # Reduce by key\n",
        "print(\"Reduced by Key:\", rdd_reduceby)\n",
        "\n",
        "rdd_sortby = rdd_kv.sortByKey().collect()  # Sorting by key\n",
        "print(\"Sorted by Key:\", rdd_sortby)\n",
        "\n",
        "rdd_countbykey = rdd_kv.countByKey()  # Counting elements by key\n",
        "print(\"Count by Key:\", rdd_countbykey)\n",
        "\n",
        "rdd_mapvalues = rdd_kv.mapValues(lambda x: x * 10).collect()  # Transforming values\n",
        "print(\"Map Values:\", rdd_mapvalues)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ow644Pwx2SZR",
        "outputId": "3ae7cbb9-77dc-4e85-ea62-3234a560d74e"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Grouped by Key: [('b', [2, 4]), ('c', [5]), ('a', [1, 3])]\n",
            "Reduced by Key: [('b', 6), ('c', 5), ('a', 4)]\n",
            "Sorted by Key: [('a', 1), ('a', 3), ('b', 2), ('b', 4), ('c', 5)]\n",
            "Count by Key: defaultdict(<class 'int'>, {'a': 2, 'b': 2, 'c': 1})\n",
            "Map Values: [('a', 10), ('b', 20), ('a', 30), ('b', 40), ('c', 50)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step 6: Joins on RDDs\n",
        "Creating another key-value RDD for joins.\n",
        "*  Joins allow combining two datasets based on keys.\n"
      ],
      "metadata": {
        "id": "5Cfbwtw_2eXs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data_kv2 = [(\"a\", 100), (\"b\", 200), (\"c\", 300), (\"d\", 400)]\n",
        "rdd_kv2 = sc.parallelize(data_kv2)"
      ],
      "metadata": {
        "id": "haIYPyBX2bg3"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Performing different types of joins"
      ],
      "metadata": {
        "id": "R_ilRNOX2l_Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "rdd_join = rdd_kv.join(rdd_kv2).collect()  # Inner Join\n",
        "print(\"Join RDD:\", rdd_join)\n",
        "\n",
        "rdd_left_outer = rdd_kv.leftOuterJoin(rdd_kv2).collect()  # Left Outer Join\n",
        "print(\"Left Outer Join:\", rdd_left_outer)\n",
        "\n",
        "rdd_right_outer = rdd_kv.rightOuterJoin(rdd_kv2).collect()  # Right Outer Join\n",
        "print(\"Right Outer Join:\", rdd_right_outer)\n",
        "\n",
        "rdd_full_outer = rdd_kv.fullOuterJoin(rdd_kv2).collect()  # Full Outer Join\n",
        "print(\"Full Outer Join:\", rdd_full_outer)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Nras9baZ2hbR",
        "outputId": "8d5b60d7-0c7a-4f39-d7b0-72cd73491809"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Join RDD: [('b', (2, 200)), ('b', (4, 200)), ('c', (5, 300)), ('a', (1, 100)), ('a', (3, 100))]\n",
            "Left Outer Join: [('b', (2, 200)), ('b', (4, 200)), ('c', (5, 300)), ('a', (1, 100)), ('a', (3, 100))]\n",
            "Right Outer Join: [('d', (None, 400)), ('b', (2, 200)), ('b', (4, 200)), ('c', (5, 300)), ('a', (1, 100)), ('a', (3, 100))]\n",
            "Full Outer Join: [('d', (None, 400)), ('b', (2, 200)), ('b', (4, 200)), ('c', (5, 300)), ('a', (1, 100)), ('a', (3, 100))]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step 7: Partitioning\n",
        "Checking the number of partitions.\n",
        "* RDDs are split into partitions for parallel processing."
      ],
      "metadata": {
        "id": "gCjEt_PC2scL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "num_partitions = rdd.getNumPartitions()\n",
        "print(\"Number of Partitions:\", num_partitions)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yJj3WaOR2oev",
        "outputId": "2f9fb5b1-8ca8-4a28-92d4-bcc59cc9b654"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of Partitions: 2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step 8: Aggregations\n",
        "* Fold: Aggregates using an initial zero value.\n",
        "* Aggregate: Computes sum and count, then calculates average.\n",
        "\n"
      ],
      "metadata": {
        "id": "QLPv8rML3aF_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "rdd_fold = rdd.fold(0, lambda x, y: x + y)\n",
        "\n",
        "rdd_aggregate = rdd.aggregate((0, 0),\n",
        "    (lambda acc, value: (acc[0] + value, acc[1] + 1)),\n",
        "    (lambda acc1, acc2: (acc1[0] + acc2[0], acc1[1] + acc2[1])))\n",
        "\n",
        "rdd_avg = rdd_aggregate[0] / rdd_aggregate[1]\n",
        "\n"
      ],
      "metadata": {
        "id": "Y-6s2cYo3an2"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step 9: Caching & Persistence\n",
        "* Caching stores RDD in memory for better performance."
      ],
      "metadata": {
        "id": "LtTbsD7K3fWg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "rdd_cached = rdd.cache()\n",
        "rdd_persisted = rdd.persist()"
      ],
      "metadata": {
        "id": "sfeBnP5_3hCQ"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step 10: Set Operations\n",
        "*  Set operations allow comparisons between RDDs."
      ],
      "metadata": {
        "id": "vrx68eyY21zy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "data2 = [5, 6, 7, 8, 9, 10, 11, 12]\n",
        "rdd2 = sc.parallelize(data2)\n",
        "\n",
        "rdd_union = rdd.union(rdd2).collect()  # Union\n",
        "print(\"Union of RDDs:\", rdd_union)\n",
        "\n",
        "rdd_intersection = rdd.intersection(rdd2).collect()  # Intersection\n",
        "print(\"Intersection of RDDs:\", rdd_intersection)\n",
        "\n",
        "rdd_subtract = rdd.subtract(rdd2).collect()  # Difference\n",
        "print(\"Difference of RDDs:\", rdd_subtract)\n",
        "\n",
        "rdd_cartesian = rdd.cartesian(rdd2).collect()  # Cartesian product\n",
        "print(\"Cartesian Product:\", rdd_cartesian)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cnVzIY4p2vYK",
        "outputId": "0874e5cc-7f2b-471a-d7f8-8f4dcdf94a88"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Union of RDDs: [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 5, 6, 7, 8, 9, 10, 11, 12]\n",
            "Intersection of RDDs: [8, 5, 9, 6, 10, 7]\n",
            "Difference of RDDs: [4, 1, 2, 3]\n",
            "Cartesian Product: [(1, 5), (1, 6), (1, 7), (1, 8), (2, 5), (2, 6), (2, 7), (2, 8), (3, 5), (3, 6), (3, 7), (3, 8), (4, 5), (4, 6), (4, 7), (4, 8), (5, 5), (5, 6), (5, 7), (5, 8), (1, 9), (1, 10), (1, 11), (1, 12), (2, 9), (2, 10), (2, 11), (2, 12), (3, 9), (3, 10), (3, 11), (3, 12), (4, 9), (4, 10), (4, 11), (4, 12), (5, 9), (5, 10), (5, 11), (5, 12), (6, 5), (6, 6), (6, 7), (6, 8), (7, 5), (7, 6), (7, 7), (7, 8), (8, 5), (8, 6), (8, 7), (8, 8), (9, 5), (9, 6), (9, 7), (9, 8), (10, 5), (10, 6), (10, 7), (10, 8), (6, 9), (6, 10), (6, 11), (6, 12), (7, 9), (7, 10), (7, 11), (7, 12), (8, 9), (8, 10), (8, 11), (8, 12), (9, 9), (9, 10), (9, 11), (9, 12), (10, 9), (10, 10), (10, 11), (10, 12)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step 11: Checkpointing\n",
        "* Saves RDD state to disk to avoid recomputation.\n"
      ],
      "metadata": {
        "id": "PV7c4sei5pTz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sc.setCheckpointDir(\"/tmp/checkpoints\")\n",
        "rdd.checkpoint()"
      ],
      "metadata": {
        "id": "dzzruMRV5u42"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "# Step 12: Broadcast Variables & Accumulators\n",
        "* Broadcast variables improve performance by sharing large read-only data across workers.\n",
        "* Accumulators aggregate values from worker nodes.\n",
        "\n"
      ],
      "metadata": {
        "id": "fyMhwj2M2-Yj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "broadcast_var = sc.broadcast([1, 2, 3, 4, 5])\n",
        "accumulator = sc.accumulator(0)\n",
        "rdd.foreach(lambda x: accumulator.add(x))\n",
        "print(\"Accumulator Value:\", accumulator.value)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tNjofKS625lv",
        "outputId": "0afb9db5-25b1-476a-802f-6f81dd27c235"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accumulator Value: 55\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step 13: Printing results"
      ],
      "metadata": {
        "id": "wnjeVw4m3Iix"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "print(\"Original RDD:\", rdd_collect)\n",
        "print(\"Mapped RDD:\", rdd_map.collect())\n",
        "print(\"Filtered RDD:\", rdd_filter.collect())\n",
        "print(\"FlatMapped RDD:\", rdd_flatmap.collect())\n",
        "print(\"Distinct RDD:\", rdd_distinct.collect())\n",
        "print(\"Sampled RDD:\", rdd_sample.collect())\n",
        "print(\"Grouped by Key:\", rdd_groupby)\n",
        "print(\"Reduced by Key:\", rdd_reduceby)\n",
        "print(\"Sorted by Key:\", rdd_sortby)\n",
        "print(\"Count by Key:\", rdd_countbykey)\n",
        "print(\"Map Values:\", rdd_mapvalues)\n",
        "print(\"Join RDD:\", rdd_join)\n",
        "print(\"Left Outer Join:\", rdd_left_outer)\n",
        "print(\"Right Outer Join:\", rdd_right_outer)\n",
        "print(\"Full Outer Join:\", rdd_full_outer)\n",
        "print(\"Number of Partitions:\", num_partitions)\n",
        "print(\"Union of RDDs:\", rdd_union)\n",
        "print(\"Intersection of RDDs:\", rdd_intersection)\n",
        "print(\"Difference of RDDs:\", rdd_subtract)\n",
        "print(\"Cartesian Product:\", rdd_cartesian)\n",
        "print(\"Fold Result:\", rdd_fold)\n",
        "print(\"Average Using Aggregate:\", rdd_avg)\n",
        "print(\"Accumulator Value:\", accumulator.value)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kETvP2d82_S6",
        "outputId": "21b1d8e3-d03c-495a-e5c6-81545f28bb36"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original RDD: [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]\n",
            "Mapped RDD: [2, 4, 6, 8, 10, 12, 14, 16, 18, 20]\n",
            "Filtered RDD: [2, 4, 6, 8, 10]\n",
            "FlatMapped RDD: [1, 10, 2, 20, 3, 30, 4, 40, 5, 50, 6, 60, 7, 70, 8, 80, 9, 90, 10, 100]\n",
            "Distinct RDD: [2, 4, 6, 8, 10, 1, 3, 5, 7, 9]\n",
            "Sampled RDD: [1, 2, 4, 5]\n",
            "Grouped by Key: [('b', [2, 4]), ('c', [5]), ('a', [1, 3])]\n",
            "Reduced by Key: [('b', 6), ('c', 5), ('a', 4)]\n",
            "Sorted by Key: [('a', 1), ('a', 3), ('b', 2), ('b', 4), ('c', 5)]\n",
            "Count by Key: defaultdict(<class 'int'>, {'a': 2, 'b': 2, 'c': 1})\n",
            "Map Values: [('a', 10), ('b', 20), ('a', 30), ('b', 40), ('c', 50)]\n",
            "Join RDD: [('b', (2, 200)), ('b', (4, 200)), ('c', (5, 300)), ('a', (1, 100)), ('a', (3, 100))]\n",
            "Left Outer Join: [('b', (2, 200)), ('b', (4, 200)), ('c', (5, 300)), ('a', (1, 100)), ('a', (3, 100))]\n",
            "Right Outer Join: [('d', (None, 400)), ('b', (2, 200)), ('b', (4, 200)), ('c', (5, 300)), ('a', (1, 100)), ('a', (3, 100))]\n",
            "Full Outer Join: [('d', (None, 400)), ('b', (2, 200)), ('b', (4, 200)), ('c', (5, 300)), ('a', (1, 100)), ('a', (3, 100))]\n",
            "Number of Partitions: 2\n",
            "Union of RDDs: [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 5, 6, 7, 8, 9, 10, 11, 12]\n",
            "Intersection of RDDs: [8, 5, 9, 6, 10, 7]\n",
            "Difference of RDDs: [4, 1, 2, 3]\n",
            "Cartesian Product: [(1, 5), (1, 6), (1, 7), (1, 8), (2, 5), (2, 6), (2, 7), (2, 8), (3, 5), (3, 6), (3, 7), (3, 8), (4, 5), (4, 6), (4, 7), (4, 8), (5, 5), (5, 6), (5, 7), (5, 8), (1, 9), (1, 10), (1, 11), (1, 12), (2, 9), (2, 10), (2, 11), (2, 12), (3, 9), (3, 10), (3, 11), (3, 12), (4, 9), (4, 10), (4, 11), (4, 12), (5, 9), (5, 10), (5, 11), (5, 12), (6, 5), (6, 6), (6, 7), (6, 8), (7, 5), (7, 6), (7, 7), (7, 8), (8, 5), (8, 6), (8, 7), (8, 8), (9, 5), (9, 6), (9, 7), (9, 8), (10, 5), (10, 6), (10, 7), (10, 8), (6, 9), (6, 10), (6, 11), (6, 12), (7, 9), (7, 10), (7, 11), (7, 12), (8, 9), (8, 10), (8, 11), (8, 12), (9, 9), (9, 10), (9, 11), (9, 12), (10, 9), (10, 10), (10, 11), (10, 12)]\n",
            "Fold Result: 55\n",
            "Average Using Aggregate: 5.5\n",
            "Accumulator Value: 55\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ZT32Sq193I_G"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}